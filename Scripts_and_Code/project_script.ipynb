{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', None)\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import seaborn as sn\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, validation_curve, learning_curve, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, mean_squared_error, plot_confusion_matrix\n",
    "from sklearn.linear_model import Lasso\n",
    "from math import *\n",
    "from statistics import *\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data set\n",
    "data = pd.read_csv('../Data_and_Documentation/37633-0001-Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all observations where dependent variable = -1 (missing)\n",
    "data = data.loc[data['Q16_4'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset only the variables of interest\n",
    "data = data[['DEM_AGE_LONG','DEM_GENDER','DEM_REGION','DEM_EDUCATION_SHORT','DEM_MARITALSTATUS_LONG','DEM_HOUSEHOLDSIZE',\n",
    " 'DEM_FAMILYINCOME_SHORT','DEM_EMPLOYMENT','DEM_ETHNICITY_LONG','Q11A','Q11B','Q15A_ATGE','Q15A_AHC','Q15A_AHI','Q15A_CE','Q15A_D',\n",
    "           'Q15A_ER','Q15A_GBM','Q15A_HITH','Q15A_L','Q15A_PCB','Q15A_TBSTLI','Q16_4']]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender is originally coded as 1 = Male, 2 = Female. Subtract 1 from this variable to make it binary\n",
    "data['DEM_GENDER'] = [x - 1 for x in data['DEM_GENDER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This merges the two forms of Q11 together. 0 = personal factors, 1 = environmental factors\n",
    "data['Q11'] = data['Q11A'].combine_first(data['Q11B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the superfluous columns, subtract 1 for the same reason as the gender variable\n",
    "data = data.drop(columns = ['Q11A','Q11B'])\n",
    "data['Q11'] = [x - 1 for x in data['Q11']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the categorical ones into dummies\n",
    "data = pd.get_dummies(data, columns=['DEM_REGION', 'DEM_EDUCATION_SHORT', \n",
    "                                     'DEM_MARITALSTATUS_LONG', 'DEM_EMPLOYMENT', \n",
    "                                     'DEM_ETHNICITY_LONG'], drop_first=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the column names to make it easier to reference for renaming in the next cell\n",
    "#data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename dummies for clarity\n",
    "data = data.rename(columns = {'DEM_AGE_LONG': 'Age', 'DEM_GENDER': 'Female', 'DEM_HOUSEHOLDSIZE': \"HHoldSize\",\n",
    "       'DEM_FAMILYINCOME_SHORT': 'HHIncome','DEM_REGION_1': 'R_NEast',\n",
    "       'DEM_REGION_2': 'Midwest', 'DEM_REGION_3': 'South', 'DEM_REGION_4': 'West',\n",
    "       'DEM_EDUCATION_SHORT_2': 'HighSchool',\n",
    "       'DEM_EDUCATION_SHORT_3': 'Assoc_Degree', 'DEM_EDUCATION_SHORT_4': '4YearDegree', \n",
    "       'DEM_MARITALSTATUS_LONG_2': 'Separated', 'DEM_MARITALSTATUS_LONG_3': 'Divorced',\n",
    "       'DEM_MARITALSTATUS_LONG_4': 'Widowed', 'DEM_MARITALSTATUS_LONG_5': 'NeverMarried',\n",
    "       'DEM_EMPLOYMENT_2': 'SelfEmployed', 'DEM_EMPLOYMENT_3': 'TempLayoff', 'DEM_EMPLOYMENT_4': 'Unemployed',\n",
    "       'DEM_EMPLOYMENT_5': 'Retired', 'DEM_EMPLOYMENT_6': 'Disabled', 'DEM_EMPLOYMENT_7': \"Other_Nonworking\",\n",
    "       'DEM_ETHNICITY_LONG_2': 'Black', 'DEM_ETHNICITY_LONG_3': 'Hispanic', 'DEM_ETHNICITY_LONG_4': 'AAPI',\n",
    "       'DEM_ETHNICITY_LONG_5': 'Indigenous', 'DEM_ETHNICITY_LONG_6': 'Other_Races'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "X = data.drop(columns = ['Q16_4'], axis = 1)\n",
    "y = data['Q16_4']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xsc = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xsc, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha = 0.5)\n",
    "lasso.fit(Xtrain, ytrain)\n",
    "lasso.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Variable': Xsc.columns, 'Lasso Coef': lasso.coef_}).sort_values(['Lasso Coef'], ascending = False)\n",
    "print(output.to_latex(index = False))\n",
    "#print(tabulate(output, tablefmt=\"pipe\", headers=\"keys\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(data['Q16_4'], [33,66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['Q16_4'], axis = 1)\n",
    "y = data['Q16_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)\n",
    "conditions = [(y <= 33), (y > 66)]\n",
    "choices = [0,2]\n",
    "y['cat_col'] = np.select(conditions, choices, default = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y['cat_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also check validation curve for max_depth between 1 and 10\n",
    "tree = DecisionTreeClassifier()\n",
    "train_scores, test_scores = validation_curve(tree, X, y, param_name='min_samples_leaf',\n",
    "                                            param_range=np.arange(70,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find training and test means\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot validation curve\n",
    "plt.plot(np.arange(70,80), train_mean, label='Train')\n",
    "plt.plot(np.arange(70,80), test_mean, label='Test')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: max_depth best test score = 5, min_samples_leaf = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize new classifier and fit\n",
    "tree = DecisionTreeClassifier(min_samples_leaf = 80, max_depth = 5)\n",
    "tree.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validate mean accuracy\n",
    "cross_val_score(tree, Xtest, ytest, cv=8).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix and output\n",
    "plot_confusion_matrix(tree, Xtest, ytest)\n",
    "#plt.savefig('dt_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output a .dot file for the tree\n",
    "dot_data = export_graphviz(tree, out_file='tree.dot', feature_names=Xtrain.columns, rotate = True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "#graph.render(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following line in the command line to produce a .png:\n",
    "\n",
    "dot -Tpng tree.dot -o tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output tree feature importances\n",
    "output_tree = pd.DataFrame({'Variable': X.columns, 'Tree_Feat': tree.feature_importances_}).sort_values(['Tree_Feat'], ascending = False)\n",
    "output_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the classifier, run the max_depth with 1-10, run the n_estimators with 100-1000 (increments of 100)\n",
    "#NOTE: The n_estimators one will take a long time\n",
    "forest = RandomForestClassifier()\n",
    "train_scores, test_scores = validation_curve(forest, X, y, param_name='n_estimators',\n",
    "                                            param_range=(100,200,300,400,500,600,700,800,900,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find training and test means\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot validation curve\n",
    "plt.plot((100,200,300,400,500,600,700,800,900,1000), train_mean, label='Train')\n",
    "plt.plot((100,200,300,400,500,600,700,800,900,1000), test_mean, label='Test')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random forest: max_depth best score = 7, n_estimators = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize rf classifier, fit to training data\n",
    "forest = RandomForestClassifier(max_depth = 7, n_estimators = 600)\n",
    "forest.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validate mean accuracy\n",
    "cross_val_score(forest, Xtest, ytest, cv = 8).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix, output to png\n",
    "plot_confusion_matrix(forest, Xtest, ytest)\n",
    "plt.savefig('rf_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view RF feature importances\n",
    "output_forest = pd.DataFrame({'Variable': X.columns, 'Forest_Feat': forest.feature_importances_}).sort_values(['Forest_Feat'])\n",
    "output_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge tree and forest features into 1 table, output into latex form \n",
    "feat_import = output_tree.merge(output_forest, on = 'Variable')\n",
    "print(feat_import.to_latex(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataframe of predictions for tree an forest\n",
    "predictions = pd.DataFrame({'tree_pred': tree.predict(Xtest), 'rf_pred': forest.predict(Xtest), 'true': ytest})\n",
    "#find number of cases where predictions are different\n",
    "predictions['same'] = np.where(predictions['tree_pred'] == predictions['rf_pred'], 0,1)\n",
    "#find number of cases where predictions are the same and are accurate\n",
    "predictions['correct'] = np.where((predictions['same'] == 0) & (predictions['tree_pred'] == predictions['true']),1,0)\n",
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct predictions\n",
    "len(predictions) - predictions['correct'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percent of correct predictions\n",
    "predictions['correct'].sum()/len(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
